#!/usr/bin/env ruby

# Generate json output by key
#
#     csv [-p profile.yml] data.csv out/
#
# The data will be generated as `out/key.json`.

require 'csv'
require 'optparse'
require 'json'

require_relative './load_profile'


options = {}
OptionParser.new do |opts|
  opts.banner = "Usage: csv [-p profile.yml] data.csv out/"

  opts.on("-p", "--profile profile.yml", "path to a profile to filter the data") do |v|
    options[:profile] = v
  end

  # opts.on("-s", "--[no-]sample", "sample history data to reduce size") do |v|
  #   options[:sample] = v
  # end
end.parse!

csv_file = ARGV[0]
out_dir  = ARGV[1]

table = {}

def median(array)
  sorted = array.sort
  len = sorted.length
  (sorted[(len - 1) / 2] + sorted[len / 2]) / 2.0
end

def process(row)
  line = []
  line[0] = row[1].to_i                                      # PR
  line[1] = row[2].strip                                     # time
  line[2] = row[3].strip                                     # commit

  array = row[6].split.map { |item| item.to_f }
  line[3] = median(array)                                    # median
  line[4] = array.min                                        # min
  line
end

CSV.foreach(csv_file) do |row|
  table[row[0]] = [] unless table.key?(row[0])

  table[row[0]].push(row)
end

if options.key?(:profile)
  profile = load_profile(options[:profile])
else
  profile = nil
end

keys =
  if profile.nil? || profile["charts"].nil? || profile["charts"].empty?
    []
  else
    profile["charts"].map { |chart| chart["lines"].map { |line| line["key"] } }.flatten
  end

table.each do |key, rows|
  next unless keys.empty? || keys.include?(key)

  File.open("#{out_dir}/#{key}.json","w") do |f|
    processed = rows.map { |row| process(row) }
    f.puts "["
    processed.each_with_index do |row, index|
      f.print(row.to_json)
      if index == processed.size - 1
         f.puts
      else
         f.puts ","
      end
    end
    f.puts "]"
  end
end
